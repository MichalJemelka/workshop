{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J0flaw7HdTLC"
   },
   "source": [
    "# Introduction\n",
    "\n",
    "The first step in our task is to obtain the data necessary for analysis. Since our company is in the early stages of development and does not have its own database, we intend to use publicly available resources.  \n",
    "  \n",
    "For this purpose, we have been recommended the website [Scrape This Site](https://www.scrapethissite.com/pages/forms/). However, before we start downloading data, it is important to carefully review the [FAQ](https://www.scrapethissite.com/faq/) section on the site. Particular attention should be paid to the restrictions on the number of requests, which is crucial for our solution.  \n",
    "  \n",
    "It is expected that after executing the code contained in this notebook, the `data/raw/` folder will be populated with data, which will serve as the source for the next stage of the project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3U3qrIFCdTLF"
   },
   "source": [
    "# Notebook Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V8i_DaiDdTLF"
   },
   "source": [
    "## Importing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "9ppX5CyndTLG"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d7zC6meddTLG"
   },
   "source": [
    "## Driver and Selenium Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "hbd1oYpUdTLG"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "DRIVER_PATH = Path(r\"C:\\Users\\mjemelka\\Desktop\\Python\\chromedriver-win64\\chromedriver-win64\\chromedriver.exe\")\n",
    "assert DRIVER_PATH.exists(), f\"ChromeDriver nenalezen: {DRIVER_PATH}\"\n",
    "\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless=new\")\n",
    "chrome_options.add_argument(\"--window-size=1920,1080\")\n",
    "\n",
    "service = Service(str(DRIVER_PATH))\n",
    "driver = webdriver.Chrome(service=service, options=chrome_options)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mgv7K-lQdTLG"
   },
   "source": [
    "# Fetching Website Content\n",
    "\n",
    "This section of the notebook contains code for fetching website content. To properly execute the task, consider the following steps:  \n",
    "- Ensure all available data on the site has been fetched by checking if there are additional data pages.  \n",
    "- Locate the data of interest on the page using `html` inspection tools.  \n",
    "- Navigate between subsequent data pages using browser mechanisms or by analyzing the `url` structure.  \n",
    "  \n",
    "> Remember to respect the query limits specified in the `FAQ`!  \n",
    "  \n",
    "Save the fetched data to the folder `data/raw/hockey_teams_page_{page_number}.html`. At this stage, we are retrieving data without processing it - analysis will be performed later.  \n",
    "  \n",
    "To fetch the `html` content of the page, you can use `browser.page_source`. Make sure the browser tool configuration (e.g., Selenium) is ready for use.  \n",
    "  \n",
    "> (Optional) If there are multiple pages to fetch, use the [zfill](https://www.programiz.com/python-programming/methods/string/zfill) function to maintain order in file names by adding leading zeros to the page numbers.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uloženo: data\\raw\\hockey_teams_page_01.html\n",
      "Uloženo: data\\raw\\hockey_teams_page_02.html\n",
      "Uloženo: data\\raw\\hockey_teams_page_03.html\n",
      "Uloženo: data\\raw\\hockey_teams_page_04.html\n",
      "Uloženo: data\\raw\\hockey_teams_page_05.html\n",
      "Uloženo: data\\raw\\hockey_teams_page_06.html\n",
      "Uloženo: data\\raw\\hockey_teams_page_07.html\n",
      "Uloženo: data\\raw\\hockey_teams_page_08.html\n",
      "Uloženo: data\\raw\\hockey_teams_page_09.html\n",
      "Uloženo: data\\raw\\hockey_teams_page_10.html\n",
      "Uloženo: data\\raw\\hockey_teams_page_11.html\n",
      "Uloženo: data\\raw\\hockey_teams_page_12.html\n",
      "Uloženo: data\\raw\\hockey_teams_page_13.html\n",
      "Uloženo: data\\raw\\hockey_teams_page_14.html\n",
      "Uloženo: data\\raw\\hockey_teams_page_15.html\n",
      "Uloženo: data\\raw\\hockey_teams_page_16.html\n",
      "Uloženo: data\\raw\\hockey_teams_page_17.html\n",
      "Uloženo: data\\raw\\hockey_teams_page_18.html\n",
      "Uloženo: data\\raw\\hockey_teams_page_19.html\n",
      "Uloženo: data\\raw\\hockey_teams_page_20.html\n",
      "Uloženo: data\\raw\\hockey_teams_page_21.html\n",
      "Uloženo: data\\raw\\hockey_teams_page_22.html\n",
      "Uloženo: data\\raw\\hockey_teams_page_23.html\n",
      "Uloženo: data\\raw\\hockey_teams_page_24.html\n",
      "Uloženo: data\\raw\\hockey_teams_page_25.html\n",
      "Další stránka nenalezena — konec.\n"
     ]
    }
   ],
   "source": [
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "raw_dir = Path(\"data/raw\")\n",
    "raw_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "page_num = 1\n",
    "while True:\n",
    "    out_path = raw_dir / f\"hockey_teams_page_{str(page_num).zfill(2)}.html\"\n",
    "    out_path.write_text(driver.page_source, encoding=\"utf-8\")\n",
    "    print(f\"Uloženo: {out_path}\")\n",
    "\n",
    "    next_buttons = driver.find_elements(By.XPATH, \"//a[contains(., 'Next') or contains(., '»')]\")\n",
    "\n",
    "    if not next_buttons:\n",
    "        print(\"Další stránka nenalezena — konec.\")\n",
    "        break\n",
    "\n",
    "    try:\n",
    "        next_buttons[0].click()\n",
    "        page_num += 1\n",
    "        time.sleep(2)\n",
    "    except Exception as e:\n",
    "        print(f\"Konec — další stránku nelze otevřít ({e})\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ycm9QC8dTLH"
   },
   "source": [
    "# Summary\n",
    "\n",
    "Downloading raw data from our source has reduced the risk of problems stemming from site updates during the extraction process. This method also offers an additional benefit: it allows easy access to the data in its original form, which is crucial if reprocessing is needed.\n",
    "\n",
    "In the next step, we will focus on extracting the necessary information from the `html` pages, which is essential for conducting the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zpětná vazba k notebooku / skriptu – Webscraping s Selenium\n",
    "\n",
    "Co je dobře\n",
    "Kód je přehledně strukturován – jasné oddělení inicializace webdriveru, hlavní smyčky a uložení výstupů.\n",
    "Použití pathlib.Path místo klasických cest je výborné – je to modernější a platformově nezávislejší způsob práce se soubory.\n",
    "Validace DRIVER_PATH.exists() s assert je praktická kontrola pro běhovou chybu – elegantně zachytí chybějící ovladač.\n",
    "Použití headless režimu a nastavení rozlišení okna je profesionální krok – eliminuje vliv prostředí při běhu automatizace.\n",
    "Struktura výstupu (data/raw/hockey_teams_page_XX.html) je dobře pojatá – připravuje data pro další fáze ETL pipeline.\n",
    "Čisté a čitelné logování pomocí print (např. „Uloženo: …“, „Další stránka nenalezena — konec.“) – vhodné pro uživatele bez debuggeru.\n",
    "\n",
    "Co zlepšit\n",
    "Chybí otevření první stránky před uložením.\n",
    "driver.page_source se čte, aniž by se předtím načetla URL.\n",
    "Doporučení – přidej před cyklus:\n",
    "driver.get(\"https://www.scrapethissite.com/pages/forms/?page_num=1&per_page=100\")\n",
    "Jinak bude první uložený soubor prázdný.\n",
    "Kód nenačítá novou stránku podle číselného parametru.\n",
    "Aktuálně se pohybuje pomocí klikání na tlačítko „Next“.\n",
    "To je funkční, ale méně robustní — stránka se může načítat pomalu nebo tlačítko může změnit text.\n",
    "Alternativa (bez Selenium klikání):\n",
    "for page_num in range(1, max_pages+1):\n",
    "    url = f\"https://www.scrapethissite.com/pages/forms/?page_num={page_num}&per_page=100\"\n",
    "    driver.get(url)\n",
    "    ...\n",
    "Doporučuji přidat explicitní WebDriverWait místo time.sleep(2)\n",
    "To je přesnější a spolehlivější způsob, jak čekat na načtení stránky:\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.TAG_NAME, \"table\")))\n",
    "Ukládání dat:\n",
    "Aktuálně se vždy přepíše out_path bez kontroly, jestli stránka není prázdná nebo duplicitní.\n",
    "Doporučuji přidat jednoduchou podmínku:\n",
    "if \"No data found\" in driver.page_source:\n",
    "    print(\"Prázdná stránka – konec.\")\n",
    "    break\n",
    "Chybí ukončení driveru po dokončení.\n",
    "Přidej na konec:\n",
    "driver.quit()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

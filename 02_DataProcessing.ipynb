{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "558XhVVXfGK8"
   },
   "source": [
    "# Introduction\n",
    "\n",
    "The purpose of this task is to extract and save information about hockey teams into JSON format, based on data from files located in the `/data/raw` directory, which were generated in the previous stage. The information to be scraped and saved includes:  \n",
    "\n",
    "- Team Name (`Team Name`),  \n",
    "- Year (`Year`),  \n",
    "- Number of wins (`Wins`),  \n",
    "- Number of losses (`Losses`),  \n",
    "- Number of overtime losses (`OT Losses` - Overtime Losses),  \n",
    "- Win percentage (`Win %`),  \n",
    "- Number of goals scored (`Goals For (GF)`),  \n",
    "- Number of goals conceded (`Goals Against (GA)`),  \n",
    "- Goal differential (`+ / -`).  \n",
    "\n",
    "Each collected record should be organized into a dictionary with the structure shown below and then added to the results list:  \n",
    "\n",
    "```python  \n",
    "{  \n",
    "    'Team Name': 'Boston Bruins',  \n",
    "    'Year': '1990',  \n",
    "    'Wins': '44',  \n",
    "    'Losses': '24',  \n",
    "    'OT Losses': '',  \n",
    "    'Win %': '0.55',  \n",
    "    'Goals For (GF)': '299',  \n",
    "    'Goals Against (GA)': '264',  \n",
    "    '+ / -': '35'  \n",
    "}  \n",
    "```\n",
    "\n",
    "Place each item into the results list.\n",
    "\n",
    "The resulting data should be saved in a file named hockey_teams.json, which will be placed in the `data/interim/` folder. This file will serve as a data source for further analysis in the next part of the workshop.\n",
    "\n",
    "> At this point, converting HTML to JSON may seem complex and unnecessary, but it aims to consolidate knowledge regarding this data structure due to its universality and prevalence not only in the world of data analysis but generally in IT as well.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6u5hG5rOfGK_"
   },
   "source": [
    "# Notebook Configuration\n",
    "\n",
    "## Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "lVWklch6fGLA"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "raw_files = sorted(glob(\"data/raw/hockey_teams_page_*.html\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E37pRB3JfGLA"
   },
   "source": [
    "# Scraping\n",
    "\n",
    "To scrape the required information from the saved files, follow these steps:\n",
    "\n",
    "1. Find all HTML files in the `data/raw` folder using the `glob` module.\n",
    "2. For each HTML file, use `BeautifulSoup` to scrape the page and extract the needed data.\n",
    "3. Save the obtained data as partially processed in the `hockey_teams.json` file located in the `/data/interim/` folder.\n",
    "\n",
    "These steps will allow for efficient processing of data from HTML files and prepare them for further analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oxAHWKh7fGLB"
   },
   "source": [
    "## List of HTML files\n",
    "\n",
    "Using the `glob` module, find all `html` files in the `data/raw` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Kd6AfGWsfGLB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nalezeno HTML souborů: 25\n",
      " - hockey_teams_page_01.html\n",
      " - hockey_teams_page_02.html\n",
      " - hockey_teams_page_03.html\n",
      " - hockey_teams_page_04.html\n",
      " - hockey_teams_page_05.html\n",
      " - hockey_teams_page_06.html\n",
      " - hockey_teams_page_07.html\n",
      " - hockey_teams_page_08.html\n",
      " - hockey_teams_page_09.html\n",
      " - hockey_teams_page_10.html\n",
      " - hockey_teams_page_11.html\n",
      " - hockey_teams_page_12.html\n",
      " - hockey_teams_page_13.html\n",
      " - hockey_teams_page_14.html\n",
      " - hockey_teams_page_15.html\n",
      " - hockey_teams_page_16.html\n",
      " - hockey_teams_page_17.html\n",
      " - hockey_teams_page_18.html\n",
      " - hockey_teams_page_19.html\n",
      " - hockey_teams_page_20.html\n",
      " - hockey_teams_page_21.html\n",
      " - hockey_teams_page_22.html\n",
      " - hockey_teams_page_23.html\n",
      " - hockey_teams_page_24.html\n",
      " - hockey_teams_page_25.html\n"
     ]
    }
   ],
   "source": [
    "RAW_DIR = Path(\"data/raw\")\n",
    "INTERIM_DIR = Path(\"data/interim\")\n",
    "INTERIM_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "html_files = sorted(RAW_DIR.glob(\"*.html\"))\n",
    "\n",
    "print(f\"Nalezeno HTML souborů: {len(html_files)}\")\n",
    "for f in html_files[:25]:\n",
    "    print(\" -\", f.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZigRm-unfGLB"
   },
   "source": [
    "## Scraping\n",
    "\n",
    "Extract data from `html` files, making sure to maintain the expected structure of a single record:\n",
    "\n",
    "```python\n",
    "{\n",
    "    'Team Name': 'Boston Bruins',\n",
    "    'Year': '1990',\n",
    "    'Wins': '44',\n",
    "    'Losses': '24',\n",
    "    'OT Losses': '',\n",
    "    'Win %': '0.55',\n",
    "    'Goals For (GF)': '299',\n",
    "    'Goals Against (GA)': '264',\n",
    "    '+ / -': '35'\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "ZWNiTH61fGLB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Počet záznamů: 607\n",
      "{'Team Name': 'Boston Bruins', 'Year': '1990', 'Wins': '44', 'Losses': '24', 'OT Losses': '', 'Win %': '0.55', 'Goals For (GF)': '299', 'Goals Against (GA)': '264', '+ / -': '35'}\n",
      "{'Team Name': 'Buffalo Sabres', 'Year': '1990', 'Wins': '31', 'Losses': '30', 'OT Losses': '', 'Win %': '0.388', 'Goals For (GF)': '292', 'Goals Against (GA)': '278', '+ / -': '14'}\n"
     ]
    }
   ],
   "source": [
    "def parse_html_file(path: Path):\n",
    "    \"\"\"Vrátí list záznamů z jedné HTML stránky ve formátu zadaných klíčů.\"\"\"\n",
    "    html = path.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "    table = soup.find(\"table\")\n",
    "    if table is None:\n",
    "        return []\n",
    "\n",
    "    headers = [th.get_text(strip=True) for th in table.select(\"thead th\")]\n",
    "    if not headers:\n",
    "        first_tr = table.find(\"tr\")\n",
    "        headers = [cell.get_text(strip=True) for cell in first_tr.find_all([\"th\", \"td\"])]\n",
    "\n",
    "    records = []\n",
    "    for tr in table.select(\"tbody tr\"):\n",
    "        cells = [td.get_text(strip=True) for td in tr.find_all(\"td\")]\n",
    "\n",
    "        if not any(cells):\n",
    "            continue\n",
    "\n",
    "        if len(cells) < len(headers):\n",
    "            cells += [\"\"] * (len(headers) - len(cells))\n",
    "        elif len(cells) > len(headers):\n",
    "            cells = cells[:len(headers)]\n",
    "\n",
    "        record = dict(zip(headers, cells))\n",
    "        records.append(record)\n",
    "\n",
    "    return records\n",
    "\n",
    "\n",
    "all_records = []\n",
    "for fp in html_files:\n",
    "    all_records.extend(parse_html_file(fp))\n",
    "\n",
    "print(f\"Počet záznamů: {len(all_records)}\")\n",
    "\n",
    "for r in all_records[:2]:\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4Ls8zhgBfKv_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "96tkK70QfGLB"
   },
   "source": [
    "# Summary\n",
    "\n",
    "After extracting the relevant information, the final step in preparation for analysis is to save the data to disk.\n",
    "\n",
    "### Saving the file\n",
    "Here, save the data to `data/interim/` and name the file `hockey_teams.json`\n",
    "\n",
    "> Note: Remember to import the appropriate library for handling the JSON format beforehand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "VY4qaMYpfGLC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uloženo: data\\interim\\hockey_teams.json | Počet záznamů: 607\n"
     ]
    }
   ],
   "source": [
    "INTERIM_DIR = Path(\"data/interim\")\n",
    "INTERIM_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "out_path = INTERIM_DIR / \"hockey_teams.json\"\n",
    "\n",
    "import json\n",
    "with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(all_records, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"Uloženo: {out_path} | Počet záznamů: {len(all_records)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV uloženo: data\\interim\\hockey_teams.csv\n",
      "Počet řádků: 607\n",
      "Sloupce: ['Team Name', 'Year', 'Wins', 'Losses', 'OT Losses', 'Win %', 'Goals For (GF)', 'Goals Against (GA)', '+ / -']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team Name</th>\n",
       "      <th>Year</th>\n",
       "      <th>Wins</th>\n",
       "      <th>Losses</th>\n",
       "      <th>OT Losses</th>\n",
       "      <th>Win %</th>\n",
       "      <th>Goals For (GF)</th>\n",
       "      <th>Goals Against (GA)</th>\n",
       "      <th>+ / -</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Boston Bruins</td>\n",
       "      <td>1990</td>\n",
       "      <td>44</td>\n",
       "      <td>24</td>\n",
       "      <td></td>\n",
       "      <td>0.55</td>\n",
       "      <td>299</td>\n",
       "      <td>264</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Buffalo Sabres</td>\n",
       "      <td>1990</td>\n",
       "      <td>31</td>\n",
       "      <td>30</td>\n",
       "      <td></td>\n",
       "      <td>0.388</td>\n",
       "      <td>292</td>\n",
       "      <td>278</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Calgary Flames</td>\n",
       "      <td>1990</td>\n",
       "      <td>46</td>\n",
       "      <td>26</td>\n",
       "      <td></td>\n",
       "      <td>0.575</td>\n",
       "      <td>344</td>\n",
       "      <td>263</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chicago Blackhawks</td>\n",
       "      <td>1990</td>\n",
       "      <td>49</td>\n",
       "      <td>23</td>\n",
       "      <td></td>\n",
       "      <td>0.613</td>\n",
       "      <td>284</td>\n",
       "      <td>211</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Detroit Red Wings</td>\n",
       "      <td>1990</td>\n",
       "      <td>34</td>\n",
       "      <td>38</td>\n",
       "      <td></td>\n",
       "      <td>0.425</td>\n",
       "      <td>273</td>\n",
       "      <td>298</td>\n",
       "      <td>-25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Team Name  Year Wins Losses OT Losses  Win % Goals For (GF)  \\\n",
       "0       Boston Bruins  1990   44     24             0.55            299   \n",
       "1      Buffalo Sabres  1990   31     30            0.388            292   \n",
       "2      Calgary Flames  1990   46     26            0.575            344   \n",
       "3  Chicago Blackhawks  1990   49     23            0.613            284   \n",
       "4   Detroit Red Wings  1990   34     38            0.425            273   \n",
       "\n",
       "  Goals Against (GA) + / -  \n",
       "0                264    35  \n",
       "1                278    14  \n",
       "2                263    81  \n",
       "3                211    73  \n",
       "4                298   -25  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(all_records)\n",
    "\n",
    "csv_path = INTERIM_DIR / \"hockey_teams.csv\"\n",
    "\n",
    "df.to_csv(csv_path, index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(f\"CSV uloženo: {csv_path}\")\n",
    "print(f\"Počet řádků: {len(df)}\")\n",
    "print(f\"Sloupce: {list(df.columns)}\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ZV – Zpětná vazba / Review\n",
    "Co je dobře\n",
    "Je vidět postupné zpřesňování kódu: první verze bez ošetření, pak varianta s posunem results.append(...) dovnitř smyčky, nakonec verze s try/except a kontrolou chybějící buňky. Takhle se to má učit.\n",
    "Struktura extrakce je konzistentní. Všude se držíš pojmenovaných tříd z HTML (name, year, wins, losses, pct, gf, ga, diff), takže je kód čitelný i pro někoho, kdo HTML nezná.\n",
    "U poslední verze máš správně ošetřené pole ot-losses pomocí podmínky if ot_losses else \"\". To je přesně ten typ chyby, který u reálného scraperu dělá největší problémy.\n",
    "Ukládáš do JSONu s indent=2 a ensure_ascii=False, takže výstup je jednak čitelný, jednak zvládá diakritiku.\n",
    "Na konci děláš kontrolu načtení přes pandas.read_json(...). To je dobrá praxe: nenechat se ukolébat tím, že se soubor vytvořil, ale ověřit, že jde znovu načíst.\n",
    "Co zlepšit\n",
    "Máš v jednom souboru tři až čtyři téměř stejné bloky kódu (načti HTML → BeautifulSoup → find_all(\"tr\", class_=\"team\") → smyčka → ulož JSON). To by v produkčním kódu mělo být jen jednou. Navrhuj funkční strukturu:\n",
    "def load_html(path): ...\n",
    "def parse_teams(html): ...\n",
    "def save_json(data, path): ...\n",
    "Pak v notebooku jen skládáš kroky, místo aby ses posouvala copy-paste stylem.\n",
    "Cesty jsou natvrdo na Windows:\n",
    "r\"C:\\Users\\rdpre\\Workshop_-_files\\...\"\n",
    "To je v pořádku pro tvůj počítač, ale pro sdílený repozitář nebo hodnocení je lepší použít Path a relativní cestu k repozitáři:\n",
    "from pathlib import Path\n",
    "base = Path(\"data\")\n",
    "html_path = base / \"raw\" / \"hockey_teams_page_001.html\"\n",
    "json_path = base / \"interim\" / \"hockey_teams.json\"\n",
    "Umožní to spouštět notebook i ostatním.\n",
    "V první verzi kódu máš chybu v odsazení: results.append({...}) je až za smyčkou, takže by se přidával jen poslední tým. Později jsi to opravila. Ve zpětné vazbě to zdůrazni studentům: u scrapingu jsou chyby v odsazení fatální, protože se vytvoří „správný“ JSON, ale jen s jedním záznamem.\n",
    "V několika blocích tiskneš celé results (print(results) nebo dokonce print(results[:582])). U reálnějších dat to rychle znepřehlední výstup notebooku. Vhodnější je:\n",
    "print(f\"Uloženo {len(results)} záznamů\")\n",
    "print(results[:3])\n",
    "Když už máš try/except AttributeError, je dobré si chybné řádky logovat i s obsahem řádku (ne jen pořadí). Usnadní to debugging:\n",
    "except AttributeError:\n",
    "    print(f\"Chyba při zpracování řádku {i+1}: {team}\")\n",
    "V JSONu střídáš názvy klíčů: jednou Goals for, pak Goals For (GF), jednou Goals against, pak Goals Against (GA). Pro následnou analýzu v Pandasu je lepší držet jeden styl, ideálně snake_case:\n",
    "\"team_name\": ...,\n",
    "\"year\": ...,\n",
    "\"wins\": ...,\n",
    "\"losses\": ...,\n",
    "\"ot_losses\": ...,\n",
    "\"win_pct\": ...,\n",
    "\"goals_for\": ...,\n",
    "\"goals_against\": ...,\n",
    "\"goal_diff\": ...\n",
    "nebo alespoň konzistentně stejná diakritika a velká písmena."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
